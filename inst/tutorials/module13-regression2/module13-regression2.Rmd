---
title: "Crash course on multiple regression and ANOVA in R"
tutorial:
  id: "module13-regression2"
  name: "Regression in R"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
author: Justin Luningham
description: "Regression in R."
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(MASS)
library(car)
library(emmeans)
library(afex)
library(kableExtra)
library(jtools)
library(infer)
library(moderndive)
library(learnr)
library(report)
library(rempsyc)
library(broom)
library(data.table)
library(flextable)
library(rstatix)
library(ggpubr)
library(tidyverse)
library(tutorial.helpers)
library(datarium)
library(GGally)
options(repos = c(CRAN = "https://cran.rstudio.com"))
if (!requireNamespace("gradethis", quietly = TRUE)) {
  learnr::tutorial_warning(
    "This tutorial uses the **gradethis** package to provide feedback.  
    It looks like you don’t have gradethis installed yet.  
    Please run this in your console:
    
    remotes::install_github('rstudio-education/gradethis')"
  )
} else {
  library(gradethis)
  gradethis::gradethis_setup()  # optional: standardizes grading defaults
}

set.seed(144445)
one_sample <- tibble(first_walk = round(rnorm(50, 12.8, 2.5),1))
raw_pairs<-mvrnorm(25, mu = c(14, 12.8), Sigma = cbind(c(2.5, 1), c(1, 2.5)))

paired_samples <- tibble(sib1 = round(raw_pairs[,1],1), sib2 = round(raw_pairs[,2],1), famID=1:25)

paired_long <-paired_samples |> pivot_longer(cols = c(sib1, sib2), values_to = "first_walk", names_to = "sibling")

two_sample<-tibble(control = round(rnorm(50, 14, 2.5),1), intervention = round(rnorm(50, 13, 2.5 ),1))

two_sample_long <- two_sample |> 
  pivot_longer(cols = c(control, intervention), # or, cols = everything()
              values_to = "first_walk", names_to = "group")

#dat <- read_delim("~/Downloads/Tab10-2.txt", 
#    delim = "\t", escape_double = FALSE, 
#    trim_ws = TRUE)

attr(stress$score, "label") <- "Stress Score"
attr(stress$age, "label") <- "Age"

#contrasts(stress$treatment) <- contr.sum(2)
#contrasts(stress$exercise) <- contr.sum(3)

fit0 <- lm(score ~ age, stress)

mod<- lm(score ~ age + treatment, stress)
fit1 <- lm(score ~ treatment + exercise + age, stress)

fit3 <- aov_ez(
  "id", "score", stress,
  between = c("treatment","exercise"),
  covariate = "age",
  factorize = FALSE
)

gss_dat <- GSSvocab |> filter(year == "2016")
```


```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```


## Multiple Regression
###

In practice, we rarely rely on simple regression models alone - psychological and behavioral research is much more complex than that. Of course, *multiple regression* extends the linear model to handle multiple predictors. 

Multiple regression still requires independent observations, or one row per person and only one outcome $Y$. However, we can include multiple $X$ terms. The most basic form has two predictors: 

###

$$ Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i}+ \varepsilon_i$$ 
$Y_i$ is still the outcome variable for person $i$ and $\varepsilon_i$ is still the error for each person, assumed to follow a normal distribution with mean of 0 and constant variance. The intercept is now the expected value of $Y$ when *both* $X$ variables equal 0. 

###

$\beta_1$ is the expected change in $Y$ per one unit change in $X_1$, *controlling for* $X_2$. Statistically, this means we examine how $Y$ changes as $X_1$ changes if we could somehow make $X_1$ vary while keeping $X_2$ fixed. 

###

Imagine if we took out the part of $X_2$ that overlaps with both $Y$ and $X_1$, and then did the regression on these unique parts of $Y$ and $X_1$. This is the regression coefficient obtained in multiple regression.

$\beta_1$ can also be thought of as the expected change in $Y$ per unit change in $X_1$ at a fixed value of $X_2$, with the caveat that the effect of $X_1$ is constant across all values of $X_2$.

### 

Let's examine this explicitly in `R`. As an example, we will revisit the `stress` study from the `datarium` package. Let's look at the effect of both `age` and `treatment` on the stress `score`. We can simply add terms in the `formula` portion of the model with `+`. 

```{r reg1, exercise = TRUE}
fit0 <- lm(score ~ age, stress)
tidy(fit0)
mod<- lm(score ~ age + treatment, stress)
tidy(mod)
```

### 

Accounting for effect of treatment, one year increase in age leads to an expected 0.934 unit increase in stress. When comparing two people from the control group that are one year apart, their expected difference in stress is 0.934. This same difference is expected for two people from the treatment group. 

Note that the esimated effect for age is somewhat different. This is because there is some overlap between treatment and stress and/or treatment and age. Adding the treatment variable adjusts for this overlap.

### 

Let's use some quick programming to demonstrate the definition of the controlled effect being "the regression on the unique parts of $Y$ and $X_1$."

```{r reg2, exercise = TRUE, exercise.setup = "reg1"}
# Residualize stress on treatment - 
#this is what's left over in score after X2
rY <- lm(score ~ treatment, data = stress)$residual
# Residualize age on treatment - the part of X1 separate from X2 
rX <- lm(age ~ treatment, data = stress)$residual

tidy(lm(rY ~ rX)) |> filter(term == "rX")
tidy(mod)|> filter(term == "age")
```

(The standard error changes slightly because of the original model and the `rX` model having different degrees of freedom.)

```{r quiz1, echo = FALSE}
question_text("Notes to self on residualized model interpretation (optional)",
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

This illustrates that in multiple regression, the coefficients are actually "partial regression coefficients," or the simple association fitted to "parts" of the data after adjusting for other variables.


###

Let's use multiple regression to investigate the stress data further. Below, I introduce the function `ggpairs` from the `GGally` library. This is like the base function `pairs` for visualization multiple bivariate relationships, but it's enhanced a bit: 

```{r reg3, exercise = TRUE}
library(GGally)
ggpairs(stress)
```

### 

As we increase variables, the relationships become a bit harder to see. The `id` variable doesn't really make sense, so let's remove that column before `ggpairs` with some piping.

```{r reg4, exercise = TRUE}
library(GGally)
stress |> ___() |> ___()
```

###

We can also make the axis labels a little easier to see. One option is to add them to the diagonal with `axisLabels = "internal"` argument. 

###

Let's examine the effects of both treatment and exercise, accounting for age. We can add all three terms to the `formula` part of `lm`. As in our last module, this will add two dummy variables for moderate or high exercised compared to low exercise. 

```{r reg5, exercise = TRUE}
fit1 <- lm(___, stress)
tidy(fit1)
```

```{r reg5-2, include = F}
fit1 <- lm(score ~ treatment + exercise + age, stress)
mod<- lm(score ~ age + treatment, stress)
#tidy(fit1)
```

```{r quiz2, echo = FALSE}
question_text("Notes to self on fit1 model interpretation:",
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```


###

Interpretation:

* SKY treatment leads to reduced stress, controlling for age and exercise level: 4.33 lower stress on average
* high levels of exercise reduce stress compared to low exercise, adjusting for age and SKY effects: 9.62 lower stress on average
* no difference between moderate and low exercise 
* stress increases with age, regardless of treatment or exercise: about 0.5 points per year

### 

Before diving deeper into interpreting this model, we need to ask the question: "is this model actually better than the first one?", i.e., does adding `exercise` improve the model fit? 

We have a hint that the answer is yes because of the significant coefficients, but the two classical ways to determine this are 1) a global model comparison, seeing if the overall fit of the second model is significantly better than the first, most often conducted by 1a) an $F$ test or 1b) a likelihood ratio test, and 2) improvements in *adjusted* $R^2$. 

### `anova()` function for model comparison

To test overall model comparisons, we can use the `anova()` function to calculate either an $F$ statistic for the $F$ test or a $\chi^2$ statistic for the LRT. 

Conceptually, we can think of the $F$ test as

$$F = \frac{ \text{increase in error per increase in df}}{\text{minimal error per df}}$$ 

The numerator contains the difference in sums of squared residuals between the simpler model and the more complex model. However, the simpler model can never have a reduction in error. It will always be the same or larger, so we divide the reduction in error due to the full model by the number of additional parameters in the full model. This is captured as the difference in degrees of freedom between the models, $\Delta df$. 

The denominator is the sums of squares errors of the full model divided by its total degrees of freedom. This serves as a benchmark or baseline error per $df$.

###

If the models fit the same, we expect the errors per $df$ to be the same in the long run, and $F = 1$. This is the null hypothesis of the $F$ test. A large $F$ means that the errors are greatly reduced by considering a more complex model. 

The $F$ test is used when the models are estimated by ordinary least squares (OLS). 

### 

### Likelihood ratio test

The likelihood ratio test (LRT) is more flexible than the $F$ test, but it has the same goal. The major distinction between the two is that LRT is applied when the models are estimated using maximum likelihood estimation (MLE). MLE is more flexible than least squares and can be used for a wider range of models, such as generalized linear models and mixed-effects models. However, there is "no free lunch" in statistics - MLE requires additional, stronger assumptions than OLS.

###

MLE assumes a probability density function for the data, such as a normal distribution, and then calculates the total value of the density over all data points. The LRT is a ratio of the likelihoods based on estimates of the simpler model to the more complex model. You may have seen output such as "-2LL" before; this is because we usually work with the log likelihoods for mathematical convenience, and the constant "-2" is multiplied by the ratios for the test. 

###

Note for both approaches, the models need to be nested, meaning one model is a subset of the other. Usually, this means that one can arrive at the simpler model by setting one or more parameters of the full model to zero.

### 

Below, run the `anova` function on the two models `mod, fit1` ("smaller" model first). The default is to apply the $F$ test. For the LRT, add the argument `test = "LRT"`. 

```{r reg6, exercise = TRUE, exercise.setup = "reg5-2"}
anova(mod, fit1)
anova(mod, fit1, test = "LRT")
```

```{r quiz3, echo = FALSE}
question_text("Notes to self on interpreting the likelihood ratio test for our two models:",
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```


### adjusted $R^2$

The other tool for comparing models is adjusted $R^2$. Recall that $R^2$ is the proportion of the variance in $Y$ that is accounted for by the model. When comparing two models, we examine if the larger model with more terms added results in a meaningful larger $R^2$. 

As we just laid out above, adding predictors will always increase the sums of squares explained by the model, even if just by chance. Similarly, $R^2$ will never get worse as predictors are added to a prior model. 

Adjusted $R^2$ is simply a modified calculation that takes into account the total number of predictors in the model. Adjusted $R^2$ *can* decrease if predictors with no real effect are added to a model. Therefore, adjusted $R^2$ is a better tool to judge model comparisons. 

###

$R^2$ and adjusted $R^2$ are given by the `summary()` function. We can also extract specific elements using the `$` operator to avoid large outputs. 

```{r reg7, exercise = TRUE, exercise.setup = "reg5-2"}
summary(mod)$adj.r.squared
summary(fit1)$adj.r.squared
```

###

All considered, we can see that adding exercise provides a substantial improvement to model fit. The $R^2_{adj}$ increases by 26% when adding exercise! These three variables explain 57.6% of the variance in stress.

(note that this is much higher than we typically expect in psychology: usually 0.02, 0.13, 0.25 are considered small, medium, and large)

### Model plots

Let's look at some ways to interpret our model effects. Last time we leared about `effect_plot()` from the `jtools` library. This will help to plot effects of each variable: 

```{r reg8, exercise = TRUE, exercise.setup = "reg5-2"}
library(jtools)
effect_plot(fit1, 
            pred =___,  #start with age
            interval = TRUE, plot.points = TRUE
            )
effect_plot(fit1, 
           pred = ___, #exercise
           ___, #same options as above
           jitter=.1)
```

Hm. The regression line for age and the predicted mean for some exercise groups does not seem to align with the data. What's going on? 


### 

The regression line and predicted group means depicted here are calculated after controlling for the other variables in the model; however, the data points reflect the raw data. 

An alternative (and pretty cool) way to look at the effect of each variable is with plots called *partial residual plots*, or sometimes referred to as "component plus residual" plots. These plot the model residuals plus the effect of a single predictor variable rather than the original data. 

###

Here are sompe plots and accompanying code to demonstrate this concept: 

```{r, echo = T}
effect_plot(fit0, pred = age,plot.points = T) + 
  annotate("label",x = 70 - 0.7, y = 88, hjust = 0,size = 3.8,
           label = str_wrap("Linear predictor of age to stress in the simple regression model, where age is the only predictor", 
                            width=23))

effect_plot(fit1, pred = age, plot.points = T) + 
  annotate("label",x = 70 - 0.7, y = 84, hjust = 0,size = 3.8,
           label = str_wrap("Linear predictor of age to stress (original scores) in the multiple regression model", 
                            width=23))

effect_plot(fit1, pred = age, plot.points = T, 
            partial.residuals = T, 
            colors="firebrick4") + 
  annotate("label",x = 70 - 0.7, y = 83, hjust = 0,size = 3.8,
           label = str_wrap("Linear predictor of age to the partial residuals,
                            adjusting for effects of treatment + exercise", 
                            width=23)) + ylim(c(65,100))
```


```{r quiz4, echo = FALSE}
question_text("Notes to self on `effect_plot()` results:",
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```


###

Let's see what the partial residual plot looks like for exercise:

```{r reg9, exercise = TRUE, exercise.setup = "reg5-2"}
effect_plot(fit1, 
           pred = ___, 
           ___)
```

That makes a lot more sense. 

###

Let's also plot the predicted `treatment` effect from our model: 

```{r reg10, exercise = TRUE, exercise.setup = "reg5-2"}

```

### 

Finally, let's look at another way to interpret model effects called *estimated marginal means* (EMM). The marginal mean is the average value of $Y$ for one particular predictor, averaging over the other predictor(s). EMMs calculate these marginal mean values from a particular model, including the estimated effects of all variables and the estimated error variance. 

In our example, EMMs entail calculating the predicted means for treatment = no and treatment = yes groups *after adjusting for the other variables*. This is different from looking at the means of treatment groups in the data overall. 

###

One convenient package to do this in `R` is called `emmeans`. It can extract marginal mean values from many different types of models, but it is particularly useful for `lm` and ANOVA models. Below, we'll look at the means of exercise from the model compared to the means of the original (unadjusted) data.

`emmeans` requires the model fit object and some kind of specification. This can be a character vector of variables for EMMs or a formula specification. 

```{r reg11, exercise = TRUE, exercise.setup = "reg5-2"}
library(emmeans)
emmeans(fit1, "treatment")
emmeans(fit1, ~ treatment) #equivalent

##compare to raw summary data
stress |> 
  ___ > 
  ___(mean(score),sd(score)/sqrt(60))

```

The adjusted estimates are not far from the raw variables.

###

How about for exercise:

```{r reg12, exercise = TRUE, exercise.setup = "reg5-2"}
emmeans(fit1, ~ exercise) 
stress |> group_by(exercise) |> 
  summarize(mean(score))
```

A little more adjustment here. 

###

Partial residual plots (above) can help us to identify areas of misfit, such as predictors where the association may be non-linear when the partial residuals do not align with the linear trend. 

For completeness, we can also check the residuals against the fitted values as before. We hope to see residuals centered around zero with a constant amount of variation over the range of `x`. 

What function did we learn last time for extracting model fit information, such as predicted values and residuals?

```{r reg13, exercise = TRUE, exercise.setup = "reg5-2"}
___(fit1) |>
  ggplot(aes(x = .fitted, y = .resid))+
  geom_point() +geom_smooth(method = "lm")

___(fit1) |>
    ggplot(aes(x = seq_along(.cooksd), y = .cooksd)) +
    geom_col()
```

The 51st row is more influential than others, but the Cook's Distance is not particularly large.

## Interaction Effects (moderation) & ANOVA
###

Suppose the researcher originally proposed that regular exercise would actually enhance the SKY intervention regimen - in other words, exercise will modify the treatment effect. 

Statistically, the researcher is proposing an interaction effect between the two variables, also called moderation. A significant interaction means that the effect of one variable changes as a function of the other variable. 

###

Below, fit a new `lm` model, but in the formula, include `treatment * exercise` instead of `treatment + exercise`. Call the new fit object `fit2`. Then, view the summary of the result. 

```{r int1, exercise = TRUE}
fit1 <- lm(score ~ treatment + exercise + age, stress)
```

There are some critical issues to note here: 

* notice that we have several different "pieces" of the interaction effect that we are after - `lm` runs tests on very specific comparisons of levels of the factors using internal contrast codes for each cross-tabulation of the factors
* that's complex, but the take-home is that the overarching question of "is the effect of treatment different at different levels of exercise?" is a *joint* hypothesis, and it cannot be answered by a single effect comparison

To conduct a *joint* test for interactions between categorical variables, we need to use ANOVA methods.

###

The default `anova()` or `aov()` functions are actually not appropriate for most ANOVA analyses - this is one major limitation of `R` compared to other software. Without getting too far into the weeds...there are several ways to calculate the sums of squares for a model with categorical predictors. The primary ones are called Type I, II, and III sums of squares. Type I is considered the worst option, but it is the only method available in `anova(lm())`. 

###

One option is to, use the `Anova(lm())` function from `car` package. This has arguments of `type = 2` or `type = 3`, which are the correct ways to calculate sums of squares. 

###

Another option is to use a package designed for ANOVA/ANCOVA models. One that I like is called `afex`. It has a few different primary functions, but the `aov_ez()` function is mean to provide an easy interface for ANOVA models. It requires an ID column, even for a fully between-subjects design, but otherwise is pretty simple. The main arguments are:

```
aov_ez(
id, dv, #characters
data, 
between = NULL, #character or character vector
within = NULL, 
covariate = NULL, 
factorize = TRUE # F if covariate is continuous
)
```

### 

Let's apply it to our data: 

```{r int2, exercise = TRUE}
fit3 <- aov_ez(
  "id", "score", stress,
  between = c("treatment","exercise"),
  covariate = "age",
  factorize = FALSE
)
fit3
```

###

We get the overall test for each factor (called main effects) and the joint test of the interaction. 

**Important: we always interpret the interaction in the overall $F$ test first.** If the interaction is significant, the main effects are not interpretable on their own. 

###

Other issues with the `lm()` using categorical interaction terms:

* the regression coefficients can change depending on how the internal factor coding is assigned
* instead, we can conduct the tests in a different way - comparing the "cell means" of stress, where a cell is the combination of treatment $\times$ exercise:

| **Treatment** | **Low Exercise** | **Moderate Exercise** | **High Exercise** |
|--------------|------------------|-----------------------|------------------|
| **No**       | μ<sub>No,Low</sub>        | μ<sub>No,Mod</sub>         | μ<sub>No,High</sub>       |
| **Yes**      | μ<sub>Yes,Low</sub>       | μ<sub>Yes,Mod</sub>        | μ<sub>Yes,High</sub>      |

(note: in our model, the μ's are "age-adjusted")

* the cell means comparisons do *not* depend on how the factors are coded internally 

### 

If the interaction effect is significant, then we want to compare different levels of exercise within the treatment = Yes and treatment = No groups, separately. Remember, the interaction effect means that the effect of exercise is different at different levels of treatment. 

First, we could test for a "simple main effect", which tests if the exercise factor has an overall effect within each level of treatment. This is done with a function called `joint_tests()` from `emmeans`. Provide the model and an argument `by = "factorB"` to test the effect of "factor A" in specific levels of `factorB`.

```{r int3-1, exercise = TRUE, exercise.setup = "int2"}
joint_tests(fit3, by = "treatment")
```

###

These are both significant, so we would conduct specific exercise comparisons within the treatment levels.

For `emmeans`, we can modify the formula argument to ask for estimated marginal means of factor A **conditional on** factor B with the following: `emmeans(model, ~ A | B)`. For our data:

```{r int3, exercise = TRUE, exercise.setup = "int2"}
emm1 <- emmeans(fit3, ~ exercise | treatment)
emm1

#emmeans(fit3, "exercise", by = "treatment") #equivalent
```

### 

There are many different types of follow-up comparisons we can make in these contexts, but usually, we are interested in pairwise comparisons of different factor $A$ levels within $B$ levels. With the `emm1` object, we can use the function `pairs` from `emmeans` to conduct all pairwise comparisons:

```{r int4, exercise = TRUE, exercise.setup = "int3"}
pairs(___)
#emmeans(fit3, pairwise ~ exercise | treatment) #equivalent, but more info
```

###

`emmeans` and `afex` have built-in functionality for creating interaction plots based on the resulting model. 

* `afex` uses `afex_plot()`, which requires the model, the `x` variable, and the `trace` or grouping variable
* `emmeans` uses `emmip()`, which requires the model or the result of `emmeans` and the formula 

Here are two examples: 


```{r int5, exercise = TRUE, exercise.setup = "int2"}
#afex:
afex_plot(fit3, x="exercise", 
          trace = "treatment")

#emmeans:
emmip(fit3, ~ exercise | treatment,
      CIs = TRUE)
```

Both plots are built on `ggplot`, so we can add layers to customize them. Personally, I think the `afex_plot` is nicer. 

###

Below, switch around the `x` and `trace` arguments in `afex_plot()`, and add `theme_classic`. 

```{r int5-1, exercise = TRUE, exercise.setup = "int2"}

```

###

See [this really helpful documentation](https://cran.r-project.org/web/packages/afex/vignettes/afex_plot_introduction.html) on customizing the `afex_plot()` output. We can do all kinds of things within `afex_plot` or by adding layers. 

Here is one example: the default geometric object for the data points in the background is `geom_point`. We can change this in `afex` with the argument `data_geom`: 

```{r int6, exercise = TRUE, exercise.setup = "int2"}
#afex:
afex_plot(fit3, x="exercise", 
          trace = "treatment",
          data_geom = geom_boxplot)
```

###

We can make it even nicer using tools we've learned this semester: 

```{r int7, exercise = TRUE, exercise.setup = "int2"}
#afex:
afex_plot(fit3, x="exercise", 
          trace = "treatment",
mapping = c("shape", "color"), #NEW
data_geom = geom_violin
) + 
 theme_classic() + 
 labs(y = "Stress Score", 
 x = "Exercise group", 
 shape = "SKY Intervention",
 title = "SKY meditation enhances the stress-reduction benefits of exercise",
 caption = "Predicted means adjusted for participant age")
```

###

In the remaining sections, I present some example code and output for different types of ANOVA applications. In the interest of time, we won't dissect them all. 

### One-way Between Subjects 

Using the stress data, let's perform ANOVA of the `exercise` factor. 

```{r int8, exercise = TRUE, exercise.setup = "int2"}
one_way <- aov_ez(
"id", 
"score",
stress,
between = "exercise"
)
one_way
emm_one<-emmeans(one_way, ~ exercise)
emm_one
pairs(emm_one)
afex_plot(one_way, x = "exercise")
```

Note: `ges` is "generalized eta squared", an effect size measure similar to $R^2$ but designed for factorial designs, especially involved within- or mixed within-between factors.

compare this to the simple `lm`: 

```{r int9, exercise = TRUE}
coefficients(lm(score ~ exercise, stress))
```

Interpretation: the exercise factor is significant for explaining differences in stress scores. Follow-up tests reveal that the high exercise group has a significantly lower average stress compared to both low and moderate groups. The low and moderate groups do not differ. 

### One-way Within-subjects 

Here, we use the `selfesteem` data from the `datarium` package. The dataset contains 10 individuals' self-esteem score on three time points during a specific diet. One row per subject with `id, t1, t2, t3` columns. 

`afex` requires long format. Below I provide all the code (you will need to call for the output objects in the code, such as asking for `one_within` after it's run): 

```{r int10, exercise = TRUE}
selfesteem_long <- selfesteem |>
  pivot_longer(cols = -id, 
               names_to = "time", 
               values_to = "self_esteem")

one_within <- aov_ez("id", "self_esteem",
                   selfesteem_long, 
                   within = "time")
emm_w <- emmeans(one_within, pairwise ~ time)
p1<- afex_plot(one_within, 
x = "time", 
error = "within" #used for within-subjects designs
)
```

Interpretation: There was a significant effect of the time factor on self esteem. Follow-up tests revealed that self esteem significantly increased at each time. Self esteem was 1.8 points higher at time 2 compared to time 1 and 2.7 points higher at time 3 compared to time 2.  

### One within factor, one between factor

We will use the `depression` dataset from `datarium`. This dataset follows a treatment and control group (`treatment`) over 4 time points (`t0:t3`). Once again, we'll convert to long format.

This design with both between- and within-subject factors is often referred to as a mixed ANOVA or a split-plot design. Calculating the appropriate error terms for the various effects is a little complicated. However, `afex` handles this internally quite well. 

One other option we may consider is conducting a "simple main effects" test if there is an overall time by treatment interaction. In this case, this would mean testing the "time" factor within the specific levels of treatment before conducting specific pairwise contrasts. We can do this with the `joint_tests()` function described previously. 

Another added wrinkle here: to aid in the interpretation, I also conduct pairwise comparisons of treatment vs control at each individual time point. 


```{r int11, exercise = TRUE}
dep_long <- depression |>
  pivot_longer(cols = -c(id, treatment), names_to = "time",
               values_to = "dep_score")
#dep_long #check data format
mixed_anova <- aov_ez("id", "dep_score",
                      dep_long,
                      between = "treatment",
                      within = "time"
                      )
#mixed anova # significant interaction, so observe time trends within group
joint_tests(mixed_anova, by = "treatment")
emm_mixed <- emmeans(mixed_anova, pairwise ~ time | treatment)
# beyond our scope - could limit comparisons so that not all pairwise are tested
emm_mixed

emm_mixed2 <- emmeans(mixed_anova, pairwise ~ treatment  | time)
emm_mixed2

p2<-afex_plot(
  mixed_anova, x = "time", 
  trace = "treatment")
p2
```

The warning message on the plot indicates that the error bar calculations for a mixed or split-plot ANOVA are not perfectly correct - so we cannot decide which comparisons are significant strictly by comparing the error bars. The default uses `error = "model"`, which adds error from both within and between factors. 

Interpretation: The significant interaction between treatment and time indicates that the two groups had significantly different trends. The `joint_tests` result indicates that time has a significant time effect for each group, so we can investigate specific time trends for both groups. While both groups saw a reduction in depression scores over the course of time, the tests reveal distinct patterns for each group. The treated group saw an immediate reduction in symptoms, followed by a plateau where symptoms did not change between time 2, 3, and 4. The control group saw a slow, steady reduction from time 1, where times 3 and 4 were significantly lower than baseline. The reduction flattened out for the control group, as time 4 was not different from time 3. Further, specific comparisons of treatment within time revealed that the treatment group had significantly lower depression scores at all time points except for baseline (pre-treatment). 

## Practice Exercises
### 

Your turn! Use the code and explanations throughout the module to perform the following analyses and provide informal interpretation of the results. You can also use the optional shell document if that makes coding and trouble-shooting easier. 

### General Social Survey Data

The object `gss_data` is already loaded in our tutorial environment. This contains a subset of individuals from the General Social Survey from the National Opinion Research Center of the University of Chicago. I've filtered to only observations from 2016.

The data contain columns for 

| Column       | Value       |
| ------ |---------------| 
| year | 2016
| gender | a factor with levels female male |
| nativeBorn | Was the respondent born in the US? no or yes. |
| ageGroup | a factor with levels 18-29 30-39 40-49 50-59 60+. |
| educGroup | a factor with levels <12yrs, 12yrs, 13-15yrs, 16yrs, >16yrs |
| vocab | Number of words out of 10 correct on a vocabulary test |
| age | age of the respondent in years |
| educ | years of education. 12 = high school graduate, 16 = college graduate.|

Fit and compare the following regression models: 

1. vocab regressed on educ and age
2. vocab regressed on educ, age, and gender
3. vocab regressedon educ, age, nativeBorn, and gender

Compare the models and interpret the best-fitting one. Include some post-analysis visual checking for interpretation and/or diagnostics.

```{r activity1, exercise = T}
glimpse(gss_dat)




```


```{r quiz6, echo = FALSE}
question_text("What was the final model chosen and why? What is your interpretation of the model estimates and overall fit?",
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```


### Job Satisfaction

The `jobsatisfaction` data contain job satisfaction scores organized by gender and education level. Perform a two-way between subjects ANOVA, plot your findings, and interpret the result. 

```{r activity2, exercise = T}
glimpse(jobsatisfaction)




```


```{r quiz7, echo = FALSE}
question_text("What is the result of the two-way ANOVA? Which, if any, factors were significant, and how do we interpret their impact on job satisfaction?",
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### Anxiety data

The `anxiety` data contain measured anxiety scores at three time points across three different groups of individuals in different physical exercise conditions: grp1 (resting), grp2 (moderate), grp3 (high). 

Conduct a mixed ANOVA examining if exercise impacts anxiety trends over time. Plot the findings and report your result. 

```{r activity3, exercise = T}
glimpse(anxiety)




```


```{r quiz8, echo = FALSE}
question_text("What is the result of the split-plot/mixed ANOVA? Did anxiety trends differ by exercise condition, and if so, how?",
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```


```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
